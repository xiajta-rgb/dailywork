name: 每日自动爬取GitHub趋势数据
# 触发条件：手动触发 + 每日UTC 0点（对应北京时间8点）
on:
  # 定时触发（cron表达式：分 时 日 月 周）
  schedule:
    - cron: '0 0 * * *'
  # 手动触发（方便测试）
  workflow_dispatch:

# 工作流权限（避免权限不足）
permissions:
  contents: read

jobs:
  crawl-trend:
    # 运行环境：Ubuntu最新版（适配Playwright）
    runs-on: ubuntu-latest
    # 超时时间：脚本最长运行20分钟，这里设30分钟冗余
    timeout-minutes: 30
    
    steps:
      # 步骤1：拉取仓库中的脚本代码
      - name: 拉取仓库代码
        uses: actions/checkout@v4

      # 步骤2：配置Python环境（匹配脚本的Python版本）
      - name: 配置Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip' # 缓存依赖，加速后续执行

      # 步骤3：安装脚本依赖（如Playwright）
      - name: 安装Python依赖
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt # 需确保仓库有requirements.txt

      # 步骤4：安装Playwright浏览器及系统依赖
      - name: 安装Playwright Chromium
        run: |
          playwright install chromium
          playwright install-deps chromium # 安装浏览器所需系统库

      # 步骤5：执行爬取脚本（注入敏感信息）
      - name: 执行GitHub趋势爬取
        env:
          # 从GitHub Secrets中读取账号密码（需提前配置）
          ADMIN_USERNAME: ${{ secrets.ADMIN_USERNAME }}
          ADMIN_PASSWORD: ${{ secrets.ADMIN_PASSWORD }}
          BASE_URL: "https://trend.pythonanywhere.com"
        run: |
          # 执行脚本并保存日志
          python trend_crawler.py > crawl_log_$(date +%Y%m%d).log 2>&1
          # 打印日志（便于在Actions页面查看）
          cat crawl_log_$(date +%Y%m%d).log

      # 步骤6：上传执行日志（可选，便于后续排查问题）
      - name: 上传爬取日志
        uses: actions/upload-artifact@v4
        with:
          name: 爬取日志-${{ github.run_id }}
          path: crawl_log_*.log
          retention-days: 7 # 日志保留7天
